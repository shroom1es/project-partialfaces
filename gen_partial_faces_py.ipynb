{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63001244-8669-4896-a54e-a06e294fa70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating partial faces... : 100%|████████████| 15254/15254 [20:14<00:00, 12.56imgs/s]\n"
     ]
    }
   ],
   "source": [
    "# %load gen_partial_faces.py\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2  # open source computer vision library\n",
    "import numpy as np  # numerical operations\n",
    "from tqdm import tqdm  # progress bar utility\n",
    "\n",
    "def main(args):\n",
    "    input_dir = 'output_folder'  # input directory containing images\n",
    "    output_dir = 'partial_faces'  # output directory for saving partial faces\n",
    "    image_size = args.image_size  # target image size (square dimensions)\n",
    "    PADDING = 0.3  # padding around the face for cropping\n",
    "\n",
    "    FACTORS = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]  # different cropping factors\n",
    "    PARTS = ['lEye', 'rEye', 'Nose', 'Mouth']  # facial parts to extract\n",
    "\n",
    "    mean_face_shape_x = [0.2194, 0.7747, 0.4971, 0.3207, 0.6735]  # normalized mean x-coordinates of landmarks\n",
    "    mean_face_shape_y = [0.1871, 0.1871, 0.5337, 0.7633, 0.7633]  # normalized mean y-coordinates of landmarks\n",
    "    mean_face_shape_x[3] = 0.5 * (mean_face_shape_x[3] + mean_face_shape_x[4])  # average x-coordinate for mouth\n",
    "\n",
    "    # calculate coordinates of facial landmarks with padding\n",
    "    point_dict = {PARTS[idx]: [(PADDING + mean_face_shape_x[idx]) / (2 * PADDING + 1) * image_size,\n",
    "                               (PADDING + mean_face_shape_y[idx]) / (2 * PADDING + 1) * image_size + 15]\n",
    "                  for idx in range(4)}\n",
    "\n",
    "    # get the list of image files (jpg, png) in the input directory\n",
    "    file_paths = [os.path.join(root, file) for root, directory, files in os.walk(input_dir) \n",
    "                 for file in files if file.endswith('.jpg') or file.endswith('.png')]\n",
    "\n",
    "    # iterate over all image files and generate partial faces\n",
    "    for file_path in tqdm(file_paths, desc='generating partial faces... ', unit='imgs'):\n",
    "        try:\n",
    "            img = cv2.imread(file_path)  # read the image\n",
    "        except (IOError, ValueError, IndexError) as e:  # handle file reading errors\n",
    "            print('{}: {}'.format(file_path, e))\n",
    "        else:\n",
    "            img = img[:, :, 0:3] - 128  # normalize the image\n",
    "            for part in PARTS:  # iterate through each facial part\n",
    "                for factor in FACTORS:  # iterate through cropping factors\n",
    "                    # create a mask for the specific facial part\n",
    "                    roi = np.zeros(img.shape[0:2], dtype=np.uint8)\n",
    "                    x1 = int(point_dict[part][0] - (15 + 120 * factor))\n",
    "                    y1 = int(point_dict[part][1] - (10 + 105 * factor))\n",
    "                    x2 = int(point_dict[part][0] + (15 + 120 * factor))\n",
    "                    y2 = int(point_dict[part][1] + (10 + 105 * factor))\n",
    "                    cv2.rectangle(roi, (x1, y1), (x2, y2), 1, -1)  # draw rectangle mask over the part\n",
    "\n",
    "                    # apply the mask to the image to create a partial face\n",
    "                    partial = cv2.bitwise_and(img, img, mask=roi) + 128\n",
    "\n",
    "                    # save the partial face image\n",
    "                    output_file_path = file_path.replace(input_dir, os.path.join(output_dir, part, 'factor_' + str(factor))).replace('.jpg', '.png')\n",
    "                    if not os.path.exists(output_file_path):\n",
    "                        if not os.path.exists(os.path.dirname(output_file_path)):\n",
    "                            os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "                        cv2.imwrite(output_file_path, partial)\n",
    "\n",
    "                    # shift the partial face to center it in the output image\n",
    "                    dx = 80 - point_dict[part][0]\n",
    "                    dy = 80 - point_dict[part][1]\n",
    "                    M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "                    partial_centered = cv2.warpAffine(partial, M, (image_size, image_size), borderValue=(128, 128, 128))\n",
    "\n",
    "                    # save the centered partial face image\n",
    "                    output_file_path = file_path.replace(input_dir, os.path.join(output_dir, part + '_centered', 'factor_' + str(factor))).replace('.jpg', '.png')\n",
    "                    if not os.path.exists(output_file_path):\n",
    "                        if not os.path.exists(os.path.dirname(output_file_path)):\n",
    "                            os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "                        cv2.imwrite(output_file_path, partial_centered)\n",
    "\n",
    "class Args:\n",
    "    input_dir = 'C:\\\\Users\\\\joolia\\\\Documents\\\\project_code\\\\output_folder'  # The folder with aligned images\n",
    "    output_dir = 'C:\\\\Users\\\\joolia\\\\Documents\\\\project_code\\\\partial_faces_dataset'  # Where partial faces will be saved\n",
    "    image_size = 160\n",
    "\n",
    "# Call the main function with the arguments\n",
    "main(Args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d810b-e7ed-4fe1-b919-e0ba55139337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vgg_env)",
   "language": "python",
   "name": "vgg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
